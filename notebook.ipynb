{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQEOBZI203XS",
        "outputId": "6f9a4087-69ec-4be9-8fe3-b0049f62ff0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount our Google Drive so we can use for storage\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)   # opens an auth popup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new directory in our Drive for our dataset\n",
        "\n",
        "%%bash\n",
        "DATA_DIR=\"/content/drive/MyDrive/datasets/nyc_taxi\"\n",
        "mkdir -p \"$DATA_DIR\""
      ],
      "metadata": {
        "id": "EhbtMkvqBv9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download our dataset from Kaggle and save it in Google Drive to avoid redownloading\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os, kagglehub, pathlib\n",
        "\n",
        "# 1️⃣  Tell kagglehub to cache inside the Drive folder you made\n",
        "os.environ[\"KAGGLEHUB_CACHE\"] = \"/content/drive/MyDrive/datasets/nyc_taxi\"\n",
        "\n",
        "# 2️⃣  Download the dataset (runs only once!)\n",
        "path = kagglehub.dataset_download(\"jeffsinsel/nyc-fhvhv-data\")\n",
        "print(\"Files landed in:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_UYsSFcB7d9",
        "outputId": "c9bb8f8c-9a08-4baf-8ffa-8dd1af2ac5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.11), please consider upgrading to the latest version (0.3.12).\n",
            "Files landed in: /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at all the files we have after downloading our data\n",
        "\n",
        "import os, pathlib\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data\"\n",
        "\n",
        "# 1) Verify the directory really exists\n",
        "assert os.path.exists(DATA_DIR), f\"⚠️  Path does not exist: {DATA_DIR}\"\n",
        "\n",
        "# 2) Recursively gather all files (skip sub-dirs)\n",
        "all_files = [str(p) for p in pathlib.Path(DATA_DIR).rglob(\"*\") if p.is_file()]\n",
        "\n",
        "print(f\"Found {len(all_files)} files\")\n",
        "for f in all_files[:100]:          # show the first 20\n",
        "    print(\"  •\", f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdf9_Mp4G1-W",
        "outputId": "48a23ac2-d621-427a-dc6c-838ec4eddeb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 63 files\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/4.complete\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/data_dictionary_trip_records_hvfhs.pdf\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2019-02.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2019-03.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2019-04.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2019-05.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2019-06.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2019-07.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2019-08.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2019-09.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2019-10.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2019-11.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2019-12.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2020-01.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2020-02.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2020-03.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2020-04.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2020-05.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2020-06.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2020-07.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2020-08.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2020-09.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2020-10.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2020-11.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2020-12.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2021-01.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2021-02.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2021-03.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2021-04.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2021-05.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2021-06.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2021-07.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2021-08.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2021-09.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2021-10.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2021-11.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2021-12.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2022-01.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2022-02.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2022-03.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2022-04.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2022-05.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2022-06.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2022-07.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2022-08.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2022-09.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2022-10.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/fhvhv_tripdata_2022-11.parquet\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/taxi+_zone_lookup.csv\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/taxi_zone_map_bronx.jpg\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/taxi_zone_map_brooklyn.jpg\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/taxi_zone_map_manhattan.jpg\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/taxi_zone_map_queens.jpg\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/taxi_zone_map_staten_island.jpg\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/trip_record_user_guide.pdf\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/working_parquet_format.pdf\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/taxi_zones/taxi_zones.dbf\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/taxi_zones/taxi_zones.prj\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/taxi_zones/taxi_zones.sbn\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/taxi_zones/taxi_zones.sbx\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/taxi_zones/taxi_zones.shp\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/taxi_zones/taxi_zones.shp.xml\n",
            "  • /content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4/taxi_zones/taxi_zones.shx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge together all of our .parquet files to have 1 dataset that we can use\n",
        "\n",
        "!pip install -q \"polars[all]==1.27.1\"\n",
        "\n",
        "import polars as pl, pathlib, time, os\n",
        "\n",
        "# We'll grab the files from our drive and save them there as well\n",
        "SRC_DIR   = \"/content/drive/MyDrive/datasets/nyc_taxi/datasets/jeffsinsel/nyc-fhvhv-data/versions/4\"\n",
        "DEST_FILE = \"/content/drive/MyDrive/datasets/nyc_taxi/fhvhv_all_years.zstd.parquet\"\n",
        "\n",
        "files = [str(p) for p in pathlib.Path(SRC_DIR).rglob(\"*.parquet\")]\n",
        "print(\"Shards:\", len(files))\n",
        "\n",
        "lazy_frames = []\n",
        "for f in files:\n",
        "    lf = pl.scan_parquet(f)\n",
        "\n",
        "    # add or cast wav_match_flag so every shard has Utf8\n",
        "    if \"wav_match_flag\" in lf.columns:\n",
        "        lf = lf.with_columns(pl.col(\"wav_match_flag\").cast(pl.Utf8))\n",
        "    else:\n",
        "        lf = lf.with_columns(pl.lit(None, dtype=pl.Utf8).alias(\"wav_match_flag\"))\n",
        "\n",
        "    lazy_frames.append(lf)\n",
        "\n",
        "t0 = time.time()\n",
        "(pl.concat(lazy_frames, how=\"diagonal_relaxed\")      # tolerate missing cols\n",
        "   .sink_parquet(DEST_FILE, compression=\"zstd\"))     # streaming write\n",
        "print(f\"✅  written in {time.time()-t0:.1f}s ; size {os.path.getsize(DEST_FILE)/1e9:.2f} GB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IMrT9aTvftg",
        "outputId": "a5f2cd78-b740-4980-c8fa-dde23965a189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shards: 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-9edc1a4ca377>:16: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n",
            "  if \"wav_match_flag\" in lf.columns:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅  written in 350.7s ; size 20.53 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load full dataframe into memory, take a peek at our data to understand it,\n",
        "# then we can do our feature engineering, etc., afterwards\n",
        "\n",
        "# ╔════════════════════════════════════════════════════════════╗\n",
        "# ║  EAGER PEEK  (336 GB RAM, v2-8 TPU)                        ║\n",
        "# ╚════════════════════════════════════════════════════════════╝\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os, subprocess, time, psutil, polars as pl\n",
        "\n",
        "PARQ_DRIVE = \"/content/drive/MyDrive/datasets/nyc_taxi/fhvhv_all_years.zstd.parquet\"\n",
        "PARQ_LOCAL = \"/content/fhvhv_all_years.zstd.parquet\"   # SSD copy\n",
        "\n",
        "# ── 1️⃣ Copy to SSD with progress (only if needed) ────────────────────────\n",
        "if (not os.path.exists(PARQ_LOCAL) or\n",
        "        os.path.getsize(PARQ_LOCAL) != os.path.getsize(PARQ_DRIVE)):\n",
        "    print(\"➤  Copying Parquet from Drive to SSD …\")\n",
        "    t0 = time.time()\n",
        "    subprocess.run([\n",
        "        \"rsync\", \"-ah\", \"--info=progress2\", \"--no-inc-recursive\",\n",
        "        PARQ_DRIVE, PARQ_LOCAL\n",
        "    ], check=True)\n",
        "    print(f\"   ✅  Copied in {time.time()-t0:.1f}s\\n\")\n",
        "else:\n",
        "    print(\"✔  Parquet already on SSD — skipping copy\\n\")\n",
        "\n",
        "# ── 2️⃣ Read entire file eagerly (multithreaded) ──────────────────────────\n",
        "t0 = time.time()\n",
        "df = pl.read_parquet(PARQ_LOCAL, low_memory=False)    # uses all CPU cores\n",
        "print(f\"Loaded full table in {time.time()-t0:.1f}s | rows={len(df):,}\")\n",
        "\n",
        "# ── 3️⃣ Configure Polars console for full-width display ───────────────────\n",
        "pl.Config.set_tbl_cols(100)\n",
        "pl.Config.set_tbl_rows(10)\n",
        "pl.Config.set_fmt_str_lengths(40)\n",
        "\n",
        "print(\"\\n── First 5 rows ─────────────────────────────────────────────\")\n",
        "print(df.head(5))\n",
        "\n",
        "print(\"\\n── Null counts ──────────────────────────────────────────────\")\n",
        "print(df.null_count())\n",
        "\n",
        "print(\"\\n── Numeric describe() ───────────────────────────────────────\")\n",
        "print(df.select(pl.col(pl.NUMERIC_DTYPES)).describe())\n",
        "\n",
        "rss = psutil.Process().memory_info().rss / 1e9\n",
        "print(f\"\\n✅  Done | RAM in use {rss:.1f} GB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyDFKkSbBERZ",
        "outputId": "80347c4e-c35e-40f4-d589-2821cd88df57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "➤  Copying Parquet from Drive to SSD …\n",
            "   ✅  Copied in 1473.7s\n",
            "\n",
            "Loaded full table in 16.5s | rows=745,287,023\n",
            "\n",
            "── First 5 rows ─────────────────────────────────────────────\n",
            "shape: (5, 24)\n",
            "┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐\n",
            "│ hvf ┆ dis ┆ ori ┆ req ┆ on_ ┆ pic ┆ dro ┆ PUL ┆ DOL ┆ tri ┆ tri ┆ bas ┆ tol ┆ bcf ┆ sal ┆ con ┆ air ┆ tip ┆ dri ┆ sha ┆ sha ┆ acc ┆ wav ┆ wav │\n",
            "│ hs_ ┆ pat ┆ gin ┆ ues ┆ sce ┆ kup ┆ pof ┆ oca ┆ oca ┆ p_m ┆ p_t ┆ e_p ┆ ls  ┆ --- ┆ es_ ┆ ges ┆ por ┆ s   ┆ ver ┆ red ┆ red ┆ ess ┆ _re ┆ _ma │\n",
            "│ lic ┆ chi ┆ ati ┆ t_d ┆ ne_ ┆ _da ┆ f_d ┆ tio ┆ tio ┆ ile ┆ ime ┆ ass ┆ --- ┆ f64 ┆ tax ┆ tio ┆ t_f ┆ --- ┆ _pa ┆ _re ┆ _ma ┆ _a_ ┆ que ┆ tch │\n",
            "│ ens ┆ ng_ ┆ ng_ ┆ ate ┆ dat ┆ tet ┆ ate ┆ nID ┆ nID ┆ s   ┆ --- ┆ eng ┆ f64 ┆     ┆ --- ┆ n_s ┆ ee  ┆ f64 ┆ y   ┆ que ┆ tch ┆ rid ┆ st_ ┆ _fl │\n",
            "│ e_n ┆ bas ┆ bas ┆ tim ┆ eti ┆ ime ┆ tim ┆ --- ┆ --- ┆ --- ┆ i64 ┆ er_ ┆     ┆     ┆ f64 ┆ urc ┆ --- ┆     ┆ --- ┆ st_ ┆ _fl ┆ e_f ┆ fla ┆ ag  │\n",
            "│ um  ┆ e_n ┆ e_n ┆ e   ┆ me  ┆ --- ┆ e   ┆ i64 ┆ i64 ┆ f64 ┆     ┆ far ┆     ┆     ┆     ┆ har ┆ f64 ┆     ┆ f64 ┆ fla ┆ ag  ┆ lag ┆ g   ┆ --- │\n",
            "│ --- ┆ um  ┆ um  ┆ --- ┆ --- ┆ dat ┆ --- ┆     ┆     ┆     ┆     ┆ e   ┆     ┆     ┆     ┆ ge  ┆     ┆     ┆     ┆ g   ┆ --- ┆ --- ┆ --- ┆ str │\n",
            "│ str ┆ --- ┆ --- ┆ dat ┆ dat ┆ eti ┆ dat ┆     ┆     ┆     ┆     ┆ --- ┆     ┆     ┆     ┆ --- ┆     ┆     ┆     ┆ --- ┆ str ┆ str ┆ str ┆     │\n",
            "│     ┆ str ┆ str ┆ eti ┆ eti ┆ me[ ┆ eti ┆     ┆     ┆     ┆     ┆ f64 ┆     ┆     ┆     ┆ f64 ┆     ┆     ┆     ┆ str ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ me[ ┆ me[ ┆ ns] ┆ me[ ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ ns] ┆ ns] ┆     ┆ ns] ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
            "│ HV0 ┆ B02 ┆ B02 ┆ 201 ┆ 201 ┆ 201 ┆ 201 ┆ 245 ┆ 251 ┆ 2.4 ┆ 579 ┆ 9.3 ┆ 0.0 ┆ 0.2 ┆ 0.8 ┆ 0.0 ┆ nul ┆ 0.0 ┆ 7.4 ┆ Y   ┆ N   ┆ N   ┆ N   ┆ nul │\n",
            "│ 003 ┆ 867 ┆ 867 ┆ 9-0 ┆ 9-0 ┆ 9-0 ┆ 9-0 ┆     ┆     ┆ 5   ┆     ┆ 5   ┆     ┆ 3   ┆ 3   ┆     ┆ l   ┆     ┆ 8   ┆     ┆     ┆     ┆     ┆ l   │\n",
            "│     ┆     ┆     ┆ 2-0 ┆ 2-0 ┆ 2-0 ┆ 2-0 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 1   ┆ 1   ┆ 1   ┆ 1   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 00: ┆ 00: ┆ 00: ┆ 00: ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 01: ┆ 02: ┆ 05: ┆ 14: ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 26  ┆ 55  ┆ 18  ┆ 57  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│ HV0 ┆ B02 ┆ B02 ┆ 201 ┆ 201 ┆ 201 ┆ 201 ┆ 216 ┆ 197 ┆ 1.7 ┆ 490 ┆ 7.9 ┆ 0.0 ┆ 0.2 ┆ 0.7 ┆ 0.0 ┆ nul ┆ 2.0 ┆ 7.9 ┆ N   ┆ N   ┆ N   ┆ N   ┆ nul │\n",
            "│ 003 ┆ 879 ┆ 879 ┆ 9-0 ┆ 9-0 ┆ 9-0 ┆ 9-0 ┆     ┆     ┆ 1   ┆     ┆ 1   ┆     ┆     ┆     ┆     ┆ l   ┆     ┆ 3   ┆     ┆     ┆     ┆     ┆ l   │\n",
            "│     ┆     ┆     ┆ 2-0 ┆ 2-0 ┆ 2-0 ┆ 2-0 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 1   ┆ 1   ┆ 1   ┆ 1   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 00: ┆ 00: ┆ 00: ┆ 00: ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 26: ┆ 41: ┆ 41: ┆ 49: ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 08  ┆ 29  ┆ 29  ┆ 39  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│ HV0 ┆ B02 ┆ nul ┆ 201 ┆ nul ┆ 201 ┆ 201 ┆ 261 ┆ 234 ┆ 5.0 ┆ 215 ┆ 44. ┆ 0.0 ┆ 1.1 ┆ 3.9 ┆ 0.0 ┆ nul ┆ 0.0 ┆ 35. ┆ N   ┆ Y   ┆ N   ┆ N   ┆ nul │\n",
            "│ 005 ┆ 510 ┆ l   ┆ 9-0 ┆ l   ┆ 9-0 ┆ 9-0 ┆     ┆     ┆ 1   ┆ 9   ┆ 96  ┆     ┆ 2   ┆ 9   ┆     ┆ l   ┆     ┆ 97  ┆     ┆     ┆     ┆     ┆ l   │\n",
            "│     ┆     ┆     ┆ 2-0 ┆     ┆ 2-0 ┆ 2-0 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 1   ┆     ┆ 1   ┆ 1   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 00: ┆     ┆ 00: ┆ 01: ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 48: ┆     ┆ 51: ┆ 28: ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 58  ┆     ┆ 34  ┆ 29  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│ HV0 ┆ B02 ┆ nul ┆ 201 ┆ nul ┆ 201 ┆ 201 ┆ 87  ┆ 87  ┆ 0.3 ┆ 179 ┆ 7.1 ┆ 0.0 ┆ 0.1 ┆ 0.6 ┆ 0.0 ┆ nul ┆ 3.0 ┆ 5.3 ┆ N   ┆ Y   ┆ N   ┆ N   ┆ nul │\n",
            "│ 005 ┆ 510 ┆ l   ┆ 9-0 ┆ l   ┆ 9-0 ┆ 9-0 ┆     ┆     ┆ 4   ┆     ┆ 9   ┆     ┆ 8   ┆ 4   ┆     ┆ l   ┆     ┆ 9   ┆     ┆     ┆     ┆     ┆ l   │\n",
            "│     ┆     ┆     ┆ 2-0 ┆     ┆ 2-0 ┆ 2-0 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 1   ┆     ┆ 1   ┆ 1   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 00: ┆     ┆ 00: ┆ 00: ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 02: ┆     ┆ 03: ┆ 07: ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 15  ┆     ┆ 51  ┆ 16  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│ HV0 ┆ B02 ┆ nul ┆ 201 ┆ nul ┆ 201 ┆ 201 ┆ 87  ┆ 198 ┆ 6.8 ┆ 179 ┆ 24. ┆ 0.1 ┆ 0.6 ┆ 2.1 ┆ 0.0 ┆ nul ┆ 4.0 ┆ 17. ┆ N   ┆ Y   ┆ N   ┆ N   ┆ nul │\n",
            "│ 005 ┆ 510 ┆ l   ┆ 9-0 ┆ l   ┆ 9-0 ┆ 9-0 ┆     ┆     ┆ 4   ┆ 9   ┆ 25  ┆ 1   ┆ 1   ┆ 6   ┆     ┆ l   ┆     ┆ 07  ┆     ┆     ┆     ┆     ┆ l   │\n",
            "│     ┆     ┆     ┆ 2-0 ┆     ┆ 2-0 ┆ 2-0 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 1   ┆     ┆ 1   ┆ 1   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 00: ┆     ┆ 00: ┆ 00: ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 06: ┆     ┆ 09: ┆ 39: ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "│     ┆     ┆     ┆ 17  ┆     ┆ 44  ┆ 56  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
            "└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘\n",
            "\n",
            "── Null counts ──────────────────────────────────────────────\n",
            "shape: (1, 24)\n",
            "┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐\n",
            "│ hvf ┆ dis ┆ ori ┆ req ┆ on_ ┆ pic ┆ dro ┆ PUL ┆ DOL ┆ tri ┆ tri ┆ bas ┆ tol ┆ bcf ┆ sal ┆ con ┆ air ┆ tip ┆ dri ┆ sha ┆ sha ┆ acc ┆ wav ┆ wav │\n",
            "│ hs_ ┆ pat ┆ gin ┆ ues ┆ sce ┆ kup ┆ pof ┆ oca ┆ oca ┆ p_m ┆ p_t ┆ e_p ┆ ls  ┆ --- ┆ es_ ┆ ges ┆ por ┆ s   ┆ ver ┆ red ┆ red ┆ ess ┆ _re ┆ _ma │\n",
            "│ lic ┆ chi ┆ ati ┆ t_d ┆ ne_ ┆ _da ┆ f_d ┆ tio ┆ tio ┆ ile ┆ ime ┆ ass ┆ --- ┆ u32 ┆ tax ┆ tio ┆ t_f ┆ --- ┆ _pa ┆ _re ┆ _ma ┆ _a_ ┆ que ┆ tch │\n",
            "│ ens ┆ ng_ ┆ ng_ ┆ ate ┆ dat ┆ tet ┆ ate ┆ nID ┆ nID ┆ s   ┆ --- ┆ eng ┆ u32 ┆     ┆ --- ┆ n_s ┆ ee  ┆ u32 ┆ y   ┆ que ┆ tch ┆ rid ┆ st_ ┆ _fl │\n",
            "│ e_n ┆ bas ┆ bas ┆ tim ┆ eti ┆ ime ┆ tim ┆ --- ┆ --- ┆ --- ┆ u32 ┆ er_ ┆     ┆     ┆ u32 ┆ urc ┆ --- ┆     ┆ --- ┆ st_ ┆ _fl ┆ e_f ┆ fla ┆ ag  │\n",
            "│ um  ┆ e_n ┆ e_n ┆ e   ┆ me  ┆ --- ┆ e   ┆ u32 ┆ u32 ┆ u32 ┆     ┆ far ┆     ┆     ┆     ┆ har ┆ u32 ┆     ┆ u32 ┆ fla ┆ ag  ┆ lag ┆ g   ┆ --- │\n",
            "│ --- ┆ um  ┆ um  ┆ --- ┆ --- ┆ u32 ┆ --- ┆     ┆     ┆     ┆     ┆ e   ┆     ┆     ┆     ┆ ge  ┆     ┆     ┆     ┆ g   ┆ --- ┆ --- ┆ --- ┆ u32 │\n",
            "│ u32 ┆ --- ┆ --- ┆ u32 ┆ u32 ┆     ┆ u32 ┆     ┆     ┆     ┆     ┆ --- ┆     ┆     ┆     ┆ --- ┆     ┆     ┆     ┆ --- ┆ u32 ┆ u32 ┆ u32 ┆     │\n",
            "│     ┆ u32 ┆ u32 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ u32 ┆     ┆     ┆     ┆ u32 ┆     ┆     ┆     ┆ u32 ┆     ┆     ┆     ┆     │\n",
            "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
            "│ 0   ┆ 208 ┆ 204 ┆ 108 ┆ 207 ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 513 ┆ 414 ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 780 │\n",
            "│     ┆ 5   ┆ 294 ┆ 958 ┆ 730 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 041 ┆ 435 ┆     ┆     ┆     ┆     ┆     ┆     ┆ 377 │\n",
            "│     ┆     ┆ 792 ┆     ┆ 776 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 054 ┆     ┆     ┆     ┆     ┆     ┆     ┆ 96  │\n",
            "└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘\n",
            "\n",
            "── Numeric describe() ───────────────────────────────────────\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-164916a9b161>:45: DeprecationWarning: `NUMERIC_DTYPES` is deprecated. Define your own data type groups or use the `polars.selectors` module for selecting columns of a certain data type.\n",
            "  print(df.select(pl.col(pl.NUMERIC_DTYPES)).describe())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (9, 13)\n",
            "┌─────┬─────┬─────┬────────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐\n",
            "│ sta ┆ PUL ┆ DOL ┆ trip_m ┆ trip_ ┆ base_ ┆ tolls ┆ bcf   ┆ sales ┆ conge ┆ airpo ┆ tips  ┆ drive │\n",
            "│ tis ┆ oca ┆ oca ┆ iles   ┆ time  ┆ passe ┆ ---   ┆ ---   ┆ _tax  ┆ stion ┆ rt_fe ┆ ---   ┆ r_pay │\n",
            "│ tic ┆ tio ┆ tio ┆ ---    ┆ ---   ┆ nger_ ┆ f64   ┆ f64   ┆ ---   ┆ _surc ┆ e     ┆ f64   ┆ ---   │\n",
            "│ --- ┆ nID ┆ nID ┆ f64    ┆ f64   ┆ fare  ┆       ┆       ┆ f64   ┆ harge ┆ ---   ┆       ┆ f64   │\n",
            "│ str ┆ --- ┆ --- ┆        ┆       ┆ ---   ┆       ┆       ┆       ┆ ---   ┆ f64   ┆       ┆       │\n",
            "│     ┆ f64 ┆ f64 ┆        ┆       ┆ f64   ┆       ┆       ┆       ┆ f64   ┆       ┆       ┆       │\n",
            "╞═════╪═════╪═════╪════════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╡\n",
            "│ cou ┆ 7.4 ┆ 7.4 ┆ 7.4528 ┆ 7.452 ┆ 7.452 ┆ 7.452 ┆ 7.452 ┆ 7.452 ┆ 7.447 ┆ 3.308 ┆ 7.452 ┆ 7.452 │\n",
            "│ nt  ┆ 528 ┆ 528 ┆ 7023e8 ┆ 87023 ┆ 87023 ┆ 87023 ┆ 87023 ┆ 87023 ┆ 73982 ┆ 51969 ┆ 87023 ┆ 87023 │\n",
            "│     ┆ 702 ┆ 702 ┆        ┆ e8    ┆ e8    ┆ e8    ┆ e8    ┆ e8    ┆ e8    ┆ e8    ┆ e8    ┆ e8    │\n",
            "│     ┆ 3e8 ┆ 3e8 ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
            "│ nul ┆ 0.0 ┆ 0.0 ┆ 0.0    ┆ 0.0   ┆ 0.0   ┆ 0.0   ┆ 0.0   ┆ 0.0   ┆ 51304 ┆ 4.144 ┆ 0.0   ┆ 0.0   │\n",
            "│ l_c ┆     ┆     ┆        ┆       ┆       ┆       ┆       ┆       ┆ 1.0   ┆ 35054 ┆       ┆       │\n",
            "│ oun ┆     ┆     ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆ e8    ┆       ┆       │\n",
            "│ t   ┆     ┆     ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
            "│ mea ┆ 137 ┆ 141 ┆ 4.8128 ┆ 1116. ┆ 20.04 ┆ 0.924 ┆ 0.539 ┆ 1.688 ┆ 0.999 ┆ 0.171 ┆ 0.762 ┆ 16.25 │\n",
            "│ n   ┆ .90 ┆ .22 ┆ 53     ┆ 83816 ┆ 6085  ┆ 299   ┆ 402   ┆ 145   ┆ 182   ┆ 113   ┆ 106   ┆ 7734  │\n",
            "│     ┆ 016 ┆ 189 ┆        ┆ 6     ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
            "│     ┆ 4   ┆ 6   ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
            "│ std ┆ 75. ┆ 77. ┆ 5.5520 ┆ 797.0 ┆ 17.83 ┆ 3.493 ┆ 0.583 ┆ 1.480 ┆ 1.306 ┆ 0.635 ┆ 2.521 ┆ 14.57 │\n",
            "│     ┆ 463 ┆ 952 ┆ 69     ┆ 41155 ┆ 8784  ┆ 197   ┆ 012   ┆ 681   ┆ 181   ┆ 08    ┆ 972   ┆ 6351  │\n",
            "│     ┆ 82  ┆ 288 ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
            "│ min ┆ 1.0 ┆ 1.0 ┆ 0.0    ┆ 0.0   ┆ -1969 ┆ 0.0   ┆ 0.0   ┆ -3.0  ┆ 0.0   ┆ 0.0   ┆ 0.0   ┆ -6867 │\n",
            "│     ┆     ┆     ┆        ┆       ┆ .59   ┆       ┆       ┆       ┆       ┆       ┆       ┆ .28   │\n",
            "│ 25% ┆ 74. ┆ 75. ┆ 1.6    ┆ 578.0 ┆ 9.15  ┆ 0.0   ┆ 0.22  ┆ 0.77  ┆ 0.0   ┆ 0.0   ┆ 0.0   ┆ 7.36  │\n",
            "│     ┆ 0   ┆ 0   ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
            "│ 50% ┆ 139 ┆ 141 ┆ 2.95   ┆ 912.0 ┆ 14.93 ┆ 0.0   ┆ 0.38  ┆ 1.26  ┆ 0.0   ┆ 0.0   ┆ 0.0   ┆ 12.24 │\n",
            "│     ┆ .0  ┆ .0  ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
            "│ 75% ┆ 210 ┆ 216 ┆ 5.9    ┆ 1425. ┆ 24.8  ┆ 0.0   ┆ 0.69  ┆ 2.13  ┆ 2.75  ┆ 0.0   ┆ 0.0   ┆ 20.46 │\n",
            "│     ┆ .0  ┆ .0  ┆        ┆ 0     ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
            "│ max ┆ 265 ┆ 265 ┆ 1310.5 ┆ 24076 ┆ 8157. ┆ 1720. ┆ 203.9 ┆ 724.0 ┆ 13.75 ┆ 10.0  ┆ 1000. ┆ 4894. │\n",
            "│     ┆ .0  ┆ .0  ┆ 1      ┆ 4.0   ┆ 74    ┆ 0     ┆ 6     ┆ 8     ┆       ┆       ┆ 0     ┆ 62    │\n",
            "└─────┴─────┴─────┴────────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘\n",
            "\n",
            "✅  Done | RAM in use 192.7 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Write code to export 'df.head(5)' as a csv file\n",
        "\n",
        "df.head(5).to_csv('df_head.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "KPgiC-2gYITe",
        "outputId": "394b50c7-a4aa-48b5-a1c8-a3b52b5e2abd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a381fb58d1bc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# prompt: Write code to export 'df.head(5)' as a csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df_head.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean and add target column (target = pre-tip total)\n",
        "import polars as pl, numpy as np\n",
        "\n",
        "# In-RAM df from your peek\n",
        "df = df.filter(             # a) remove impossible rows\n",
        "        (pl.col(\"base_passenger_fare\") >= 0) &\n",
        "        (pl.col(\"trip_miles\") > 0) &\n",
        "        (pl.col(\"trip_miles\") < 200) &\n",
        "        (pl.col(\"trip_time\") > 60) &\n",
        "        (pl.col(\"trip_time\") < 4*60*60)          # <4h\n",
        "     ).with_columns(        # b) target = pre-tip total\n",
        "        (\n",
        "            pl.col(\"base_passenger_fare\") + pl.col(\"tolls\") +\n",
        "            pl.col(\"bcf\") + pl.col(\"sales_tax\") +\n",
        "            pl.col(\"congestion_surcharge\") + pl.col(\"airport_fee\")\n",
        "        ).alias(\"target_amount\")\n",
        "     )\n",
        "\n",
        "# c) Drop zones with <300 trips\n",
        "zone_counts = df.group_by(\"PULocationID\").len()\n",
        "valid = zone_counts.filter(pl.col(\"len\") >= 300)[\"PULocationID\"]\n",
        "df = df.filter(\n",
        "        pl.col(\"PULocationID\").is_in(valid) &\n",
        "        pl.col(\"DOLocationID\").is_in(valid)\n",
        "     )\n",
        "\n",
        "print(\"Rows after clean:\", len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "c6msG6ubD1M8",
        "outputId": "75033352-5e06-49e1-e5cd-6b02f3da5d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0ddc6bdc94f8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# In-RAM df from your peek\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m df = df.filter(             # a) remove impossible rows\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"base_passenger_fare\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trip_miles\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()                      # OAuth popup once"
      ],
      "metadata": {
        "id": "MzAz4_tcWcGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project nyc-taxi-ml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIoDhsTAWyXH",
        "outputId": "ff1db85d-a9da-4d9b-af50-2b6e969cab4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUCKET=\"nyc-taxi-fhv-460946772036\"            # your bucket name\n",
        "SRC=\"/content/fhvhv_all_years.zstd.parquet\"\n",
        "\n",
        "# -m  : multi-threaded\n",
        "# -o  : enable parallel composite uploads for files > 150 MB\n",
        "!gsutil -m -o \"GSUtil:parallel_composite_upload_threshold=150M\" \\\n",
        "      cp $SRC gs://$BUCKET/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkvsmNBHW1HA",
        "outputId": "833ac58e-b912-4323-9a4a-482a325b4dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file:///content/fhvhv_all_years.zstd.parquet [Content-Type=application/octet-stream]...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil -m cp /content/fhvhv_all_years.zstd.parquet gs://nyc-taxi-fhv-460946772036/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdfYYX47WEkI",
        "outputId": "72c45c2f-5f1a-43e7-e924-8d4b73cc6edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file:///content/fhvhv_all_years.zstd.parquet [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "/ [0/1 files][    0.0 B/ 19.1 GiB]   0% Done                                    \rResumableUploadAbortException: 401 Anonymous caller does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist).\n",
            "CommandException: 1 file/object could not be transferred.\n"
          ]
        }
      ]
    }
  ]
}